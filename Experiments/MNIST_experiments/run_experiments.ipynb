{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from src.utils import compute_metrics, create_autoencoder, create_tied_autoencoder, create_data_loader\n",
    "\n",
    "np.random.seed(17)\n",
    "torch.manual_seed(17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e7376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf1a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_params(path):\n",
    "    params = []\n",
    "    keys = [\n",
    "        \"activation\",\n",
    "        \"epochs\",\n",
    "        \"latent_dim\",\n",
    "        \"num_layers\",\n",
    "        \"rate_reduce\"\n",
    "    ]\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            line = line.split()\n",
    "            line[1] = int(line[1])\n",
    "            line[2] = int(line[2])\n",
    "            line[3] = int(line[3])\n",
    "            line[4] = float(line[4])\n",
    "            params.append({k: v for k, v in zip(keys, line)})\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6740d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../pytorch_data/\"\n",
    "batch_size = 256\n",
    "iters = 15\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_loader = create_data_loader(data_path, MNIST, transform, batch_size, True)\n",
    "test_loader = create_data_loader(data_path, MNIST, transform, batch_size, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"./\")\n",
    "params = get_list_params(folder / \"params.txt\")\n",
    "eval_params = get_list_params(folder / \"eval_params_vanila.txt\")\n",
    "params = [p for p in params if not p in eval_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d94434",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, p in enumerate(params, 504 - len(params)):\n",
    "    latent_dim = p[\"latent_dim\"]\n",
    "    rate_reduce = p[\"rate_reduce\"]\n",
    "    num_layers = p[\"num_layers\"]\n",
    "    activation = p[\"activation\"]\n",
    "    out_activation = None\n",
    "    epochs = p[\"epochs\"]\n",
    "    out_file = folder / f\"data/vanila_ae/ae_{j}.csv\"\n",
    "\n",
    "    df = []\n",
    "    input_dim = train_loader.dataset.data.shape[1:]\n",
    "    ae_params = {\n",
    "        \"input_dim\": input_dim,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"activation\": activation, \n",
    "        \"out_activation\": out_activation,\n",
    "        \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    }\n",
    "    layers_dim = np.array(\n",
    "        [np.prod(input_dim) // rate_reduce ** (i + 1) for i in range(num_layers)],\n",
    "        dtype=int\n",
    "    )\n",
    "    layers_dim[layers_dim < latent_dim] = latent_dim\n",
    "    ae_params[\"layers_dim\"] = list(layers_dim)\n",
    "\n",
    "    fit_params = {\n",
    "        \"optimizer\": torch.optim.Adam,\n",
    "        \"epochs\": epochs,\n",
    "        \"loss\": torch.nn.MSELoss,\n",
    "    }\n",
    "    print(\n",
    "        f\"Num epochs: {epochs} -- Latent dim: {latent_dim} -- reduce x{rate_reduce} -- L {num_layers}\"\n",
    "    )\n",
    "    for i in range(1, iters + 1):\n",
    "        print(f\"Iteration {i}\")\n",
    "        print(\"Create model\")\n",
    "        t = time.time()\n",
    "        model = create_autoencoder(ae_params, train_loader, fit_params)\n",
    "        t = int(time.time() - t)\n",
    "        print(f\"Time: {t // 60}-{t % 60}\")\n",
    "\n",
    "        print(f\"Compute metrics\")\n",
    "        metrics = compute_metrics(model, train_loader, test_loader)\n",
    "        print(f\"Loss: Train - {metrics['eval_train']:.3f} -- Test - {metrics['eval_test']:.3f}\")\n",
    "        print(f\"KNN accuracy: {metrics['accuracy']: .3f}\")\n",
    "        print(f\"KMeans v-measure: {metrics['v_measure']: .3f}\\n\\n\")\n",
    "\n",
    "        metrics[\"iteration\"] = i\n",
    "        metrics[\"epochs\"] = epochs\n",
    "        metrics[\"latent_dim\"] = latent_dim\n",
    "        metrics[\"rate_reduce\"] = rate_reduce\n",
    "        metrics[\"num_layers\"] = num_layers\n",
    "        metrics[\"activation\"] = activation\n",
    "\n",
    "        df.append(metrics)\n",
    "        del model\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df.to_csv(out_file, index=False)\n",
    "\n",
    "    with open(folder / \"eval_params_vanila.txt\", \"a\") as f:\n",
    "        s = f\"{activation} {epochs} {latent_dim} {num_layers} {rate_reduce}\\n\"\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a018b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"./\")\n",
    "params = get_list_params(folder / \"params.txt\")\n",
    "eval_params = get_list_params(folder / \"eval_params_tied.txt\")\n",
    "params = [p for p in params if not p in eval_params]\n",
    "\n",
    "alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aea994",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j, p in enumerate(params, 504 - len(params)):\n",
    "    latent_dim = p[\"latent_dim\"]\n",
    "    rate_reduce = p[\"rate_reduce\"]\n",
    "    num_layers = p[\"num_layers\"]\n",
    "    activation = p[\"activation\"]\n",
    "    out_activation = None\n",
    "    epochs = p[\"epochs\"]\n",
    "    out_file = folder / f\"data/tied_ae/ae_{j}.csv\"\n",
    "\n",
    "    df = []\n",
    "    input_dim = train_loader.dataset.data.shape[1:]\n",
    "    ae_params = {\n",
    "        \"input_dim\": input_dim,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"activation\": activation, \n",
    "        \"out_activation\": out_activation,\n",
    "        \"alpha\": alpha,\n",
    "        \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    }\n",
    "    layers_dim = np.array(\n",
    "        [np.prod(input_dim) // rate_reduce ** (i + 1) for i in range(num_layers)],\n",
    "        dtype=int\n",
    "    )\n",
    "    layers_dim[layers_dim < latent_dim] = latent_dim\n",
    "    ae_params[\"layers_dim\"] = list(layers_dim)\n",
    "\n",
    "    fit_params = {\n",
    "        \"optimizer\": torch.optim.Adam,\n",
    "        \"epochs\": epochs,\n",
    "        \"loss\": torch.nn.MSELoss,\n",
    "    }\n",
    "    print(\n",
    "        f\"Num epochs: {epochs} -- Latent dim: {latent_dim} -- reduce x{rate_reduce} -- L {num_layers}\"\n",
    "    )\n",
    "    for i in range(1, iters + 1):\n",
    "        print(f\"Iteration {i}\")\n",
    "        print(\"Create model\")\n",
    "        t = time.time()\n",
    "        model = create_tied_autoencoder(ae_params, train_loader, fit_params)\n",
    "        t = int(time.time() - t)\n",
    "        print(f\"Time: {t // 60}-{t % 60}\")\n",
    "\n",
    "        print(f\"Compute metrics\")\n",
    "        metrics = compute_metrics(model, train_loader, test_loader)\n",
    "        print(f\"Loss: Train - {metrics['eval_train']:.3f} -- Test - {metrics['eval_test']:.3f}\")\n",
    "        print(f\"KNN accuracy: {metrics['accuracy']: .3f}\")\n",
    "        print(f\"KMeans v-measure: {metrics['v_measure']: .3f}\")\n",
    "\n",
    "        metrics[\"iteration\"] = i\n",
    "        metrics[\"epochs\"] = epochs\n",
    "        metrics[\"latent_dim\"] = latent_dim\n",
    "        metrics[\"rate_reduce\"] = rate_reduce\n",
    "        metrics[\"num_layers\"] = num_layers\n",
    "        metrics[\"activation\"] = activation\n",
    "\n",
    "        df.append(metrics)\n",
    "        del model\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df.to_csv(out_file, index=False)\n",
    "\n",
    "    with open(folder / \"eval_params_tied.txt\", \"a\") as f:\n",
    "        s = f\"{activation} {epochs} {latent_dim} {num_layers} {rate_reduce}\\n\"\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f176135",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = Path(\"./\")\n",
    "params = get_list_params(folder / \"params.txt\")\n",
    "eval_params = get_list_params(folder / \"eval_params_tied_ort.txt\")\n",
    "params = [p for p in params if not p in eval_params]\n",
    "\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49870c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, p in enumerate(params, 504 - len(params)):\n",
    "    latent_dim = p[\"latent_dim\"]\n",
    "    rate_reduce = p[\"rate_reduce\"]\n",
    "    num_layers = p[\"num_layers\"]\n",
    "    activation = p[\"activation\"]\n",
    "    out_activation = None\n",
    "    epochs = p[\"epochs\"]\n",
    "    out_file = folder / f\"data/tied_ort_ae/ae_{j}.csv\"\n",
    "\n",
    "    df = []\n",
    "    input_dim = train_loader.dataset.data.shape[1:]\n",
    "    ae_params = {\n",
    "        \"input_dim\": input_dim,\n",
    "        \"latent_dim\": latent_dim,\n",
    "        \"activation\": activation, \n",
    "        \"out_activation\": out_activation,\n",
    "        \"alpha\": alpha,\n",
    "        \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    }\n",
    "    layers_dim = np.array(\n",
    "        [np.prod(input_dim) // rate_reduce ** (i + 1) for i in range(num_layers)],\n",
    "        dtype=int\n",
    "    )\n",
    "    layers_dim[layers_dim < latent_dim] = latent_dim\n",
    "    ae_params[\"layers_dim\"] = list(layers_dim)\n",
    "\n",
    "    fit_params = {\n",
    "        \"optimizer\": torch.optim.Adam,\n",
    "        \"epochs\": epochs,\n",
    "        \"loss\": torch.nn.MSELoss,\n",
    "    }\n",
    "    print(\n",
    "        f\"Num epochs: {epochs} -- Latent dim: {latent_dim} -- reduce x{rate_reduce} -- L {num_layers}\"\n",
    "    )\n",
    "    for i in range(1, iters + 1):\n",
    "        print(f\"Iteration {i}\")\n",
    "        print(\"Create model\")\n",
    "        t = time.time()\n",
    "        model = create_tied_autoencoder(ae_params, train_loader, fit_params)\n",
    "        t = int(time.time() - t)\n",
    "        print(f\"Time: {t // 60}-{t % 60}\")\n",
    "\n",
    "        print(f\"Compute metrics\")\n",
    "        metrics = compute_metrics(model, train_loader, test_loader)\n",
    "        print(f\"Loss: Train - {metrics['eval_train']:.3f} -- Test - {metrics['eval_test']:.3f}\")\n",
    "        print(f\"KNN accuracy: {metrics['accuracy']: .3f}\")\n",
    "        print(f\"KMeans v-measure: {metrics['v_measure']: .3f}\")\n",
    "\n",
    "        metrics[\"iteration\"] = i\n",
    "        metrics[\"epochs\"] = epochs\n",
    "        metrics[\"latent_dim\"] = latent_dim\n",
    "        metrics[\"rate_reduce\"] = rate_reduce\n",
    "        metrics[\"num_layers\"] = num_layers\n",
    "        metrics[\"activation\"] = activation\n",
    "\n",
    "        df.append(metrics)\n",
    "        del model\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df.to_csv(out_file, index=False)\n",
    "\n",
    "    with open(folder / \"eval_params_tied_ort.txt\", \"a\") as f:\n",
    "        s = f\"{activation} {epochs} {latent_dim} {num_layers} {rate_reduce}\\n\"\n",
    "        f.write(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
